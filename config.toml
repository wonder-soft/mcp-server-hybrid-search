# mcp-server-hybrid-search configuration

# Qdrant connection (gRPC port)
qdrant_url = "http://localhost:6334"

# Qdrant collection name
collection_name = "docs"

# Tantivy index directory
# tantivy_index_dir = "~/.mcp-hybrid-search/tantivy"

# Chunk settings
chunk_size = 1000
chunk_overlap = 200

# MCP server listen port
listen_port = 7070

# Embedding settings
# Provider: "openai" (requires OPENAI_API_KEY) or "local" (requires --features local-embed)
embedding_provider = "openai"
embedding_model = "text-embedding-3-small"
embedding_dimension = 1536
# For local embedding with multilingual-e5-small (384 dim):
#   embedding_provider = "local"
#   embedding_model = "multilingual-e5-small"
#   embedding_dimension = 384
# For local embedding with multilingual-e5-base (768 dim, better accuracy):
#   embedding_provider = "local"
#   embedding_model = "multilingual-e5-base"
#   embedding_dimension = 768

# Tokenizer for BM25 full-text search
# Options: "default", "japanese", "korean", "chinese"
# Non-default tokenizers require building with the corresponding feature:
#   cargo build --features ja   (for "japanese")
#   cargo build --features ko   (for "korean")
#   cargo build --features zh   (for "chinese")
tokenizer = "default"
